{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559b8365",
   "metadata": {},
   "source": [
    "# Drug Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a701ee6",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "**Positive(drug):** \n",
    "- Chembl ( Approved + Small Molecules + Not Withdrawn)\n",
    "- ZINC15's World Subset (Clean + In-Man)\n",
    "\n",
    "**Negative(non-drug):** \n",
    "- ZINC15(Clean + Lead-like)\n",
    "- GDB13 (Saturated Hydrocarbons & C+O & C+N subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14cebba",
   "metadata": {},
   "source": [
    "### Drug Dataset\n",
    "Generating a combined Drug dataset of Chembl's Approved drugs and Zinc15's World subset.\n",
    "\n",
    "Total Drugs in Drug combined dataset = 5901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81485aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:14:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:14:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:14:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:14:03] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 5901 to Dataset/positives/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "# Paths\n",
    "chembl_path = r\"Data/positives/chembl/raw_approved_drug_data.csv\"\n",
    "zinc_path = r\"Data/positives/zinc/world+in-man+clean.csv\"\n",
    "output_path = r\"Dataset/positives/dataset.csv\"\n",
    "\n",
    "# Load datasets\n",
    "chembl_df = pd.read_csv(chembl_path, sep=\";\")\n",
    "zinc_df = pd.read_csv(zinc_path)\n",
    "\n",
    "\n",
    "# Filter ChEMBL: small molecule & not withdrawn\n",
    "chembl_df = chembl_df[\n",
    "    (chembl_df[\"Drug Type\"].str.contains(\"Small Molecule\", case=False, na=False)) &\n",
    "    (chembl_df[\"Withdrawn Flag\"] != \"True\")\n",
    "]\n",
    "\n",
    "# Canonicalize SMILES\n",
    "def canonicalize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        return Chem.MolToSmiles(mol, canonical=True)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply to both datasets\n",
    "chembl_df[\"smiles\"] = chembl_df[\"Smiles\"].apply(canonicalize_smiles)\n",
    "zinc_df[\"smiles\"] = zinc_df[\"smiles\"].apply(canonicalize_smiles)\n",
    "\n",
    "# Drop invalid entries\n",
    "chembl_df = chembl_df.dropna(subset=[\"smiles\"])\n",
    "zinc_df = zinc_df.dropna(subset=[\"smiles\"])\n",
    "\n",
    "# Keep only canonical SMILES\n",
    "chembl_df = chembl_df[[\"smiles\"]]\n",
    "zinc_df = zinc_df[[\"smiles\"]]\n",
    "\n",
    "# Merge, deduplicate, shuffle\n",
    "combined_df = pd.concat([chembl_df, zinc_df], ignore_index=True)\n",
    "combined_df.drop_duplicates(subset=[\"smiles\"], inplace=True)\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save to file\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved: {len(combined_df)} to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef775e",
   "metadata": {},
   "source": [
    "### Non-Drug Dataset\n",
    "\n",
    "Generating a combined Non-Drug Dataset of ZINC15's Lead-like molecules and GDB13's Saturated Hydrocarbons & C+O & C+N subset\n",
    "\n",
    "Total non-drugs in combined Non-drug dataset = 5902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6feebf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 from required files in Data/negatives/gdb/SaturatedHydrocarbons\n",
      "Loaded 62 from required files in Data/negatives/gdb/CO\n",
      "Loaded 63 from required files in Data/negatives/gdb/CN\n",
      "✅ Saved 5902 non-drug SMILES to Dataset/negatives/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from rdkit import Chem\n",
    "\n",
    "# -------------------------\n",
    "# Paths and Parameters\n",
    "# -------------------------\n",
    "zinc_dir = r\"Data/negatives/zinc\"\n",
    "gdb13_g_dir = r\"Data/negatives/gdb/SaturatedHydrocarbons\"\n",
    "gdb13_co_dir = r\"Data/negatives/gdb/CO\"\n",
    "gdb13_cn_dir = r\"Data/negatives/gdb/CN\"\n",
    "drug_file = r\"Dataset/positives/dataset.csv\"\n",
    "output_file = r\"Dataset/negatives/dataset.csv\"\n",
    "\n",
    "sample_size_zinc = 2951\n",
    "sample_size_g = 984\n",
    "sample_size_co = 984\n",
    "sample_size_cn = 983\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# -------------------------\n",
    "# Canonicalization Function\n",
    "# -------------------------\n",
    "def canonicalize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            return Chem.MolToSmiles(mol, canonical=True)\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# -------------------------\n",
    "# Load known drug SMILES\n",
    "# -------------------------\n",
    "drug_df = pd.read_csv(drug_file)\n",
    "known_drugs = set(drug_df[\"smiles\"].dropna().unique())\n",
    "\n",
    "# -------------------------\n",
    "# Load ZINC15 SMILES\n",
    "# -------------------------\n",
    "zinc_smiles = set()\n",
    "for file_path in glob.glob(os.path.join(zinc_dir, \"*.smi\")):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            smiles = line.strip().split()[0]\n",
    "            if smiles.lower() == \"smiles\":\n",
    "                continue\n",
    "            canon = canonicalize_smiles(smiles)\n",
    "            if canon and canon not in known_drugs:\n",
    "                zinc_smiles.add(canon)\n",
    "\n",
    "zinc_final = random.sample(list(zinc_smiles), min(sample_size_zinc, len(zinc_smiles)))\n",
    "\n",
    "# -------------------------\n",
    "# Load GDB13 Subsets\n",
    "# -------------------------\n",
    "def load_gdb13_subset_two_phase(subset_dir, sample_size, known_drugs, required_range, optional_range):\n",
    "    selected = set()\n",
    "\n",
    "    # Phase 1: Add all from required range (e.g., 1-5)\n",
    "    for file_path in sorted(glob.glob(os.path.join(subset_dir, required_range))):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                smiles = line.strip().split()[0]\n",
    "                if smiles.lower() == \"smiles\":\n",
    "                    continue\n",
    "                canon = canonicalize_smiles(smiles)\n",
    "                if canon and canon not in known_drugs:\n",
    "                    selected.add(canon)\n",
    "\n",
    "    print(f\"Loaded {len(selected)} from required files in {subset_dir}\")\n",
    "\n",
    "    # Phase 2: Random fill from optional range (e.g., 6-9)\n",
    "    optional_pool = set()\n",
    "    for file_path in sorted(glob.glob(os.path.join(subset_dir, optional_range))):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                smiles = line.strip().split()[0]\n",
    "                if smiles.lower() == \"smiles\":\n",
    "                    continue\n",
    "                canon = canonicalize_smiles(smiles)\n",
    "                if canon and canon not in known_drugs and canon not in selected:\n",
    "                    optional_pool.add(canon)\n",
    "\n",
    "    fill_count = sample_size - len(selected)\n",
    "    if fill_count > 0:\n",
    "        selected.update(random.sample(list(optional_pool), min(fill_count, len(optional_pool))))\n",
    "\n",
    "    return list(selected)\n",
    "\n",
    "gdb_g = load_gdb13_subset_two_phase(\n",
    "    gdb13_g_dir, sample_size_g, known_drugs,\n",
    "    required_range=\"[1-5].g.smi\", optional_range=\"[6-9].g.smi\"\n",
    ")\n",
    "\n",
    "gdb_co = load_gdb13_subset_two_phase(\n",
    "    gdb13_co_dir, sample_size_co, known_drugs,\n",
    "    required_range=\"[1-5].co.smi\", optional_range=\"[6-7].co.smi\"\n",
    ")\n",
    "\n",
    "gdb_cn = load_gdb13_subset_two_phase(\n",
    "    gdb13_cn_dir, sample_size_cn, known_drugs,\n",
    "    required_range=\"[1-5].cn.smi\", optional_range=\"[6-7].cn.smi\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Final Merge & Save\n",
    "# -------------------------\n",
    "combined = pd.DataFrame(zinc_final + gdb_g + gdb_co + gdb_cn, columns=[\"smiles\"])\n",
    "combined.drop_duplicates(subset=[\"smiles\"], inplace=True)\n",
    "combined = combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "combined.to_csv(output_file, index=False)\n",
    "print(f\"✅ Saved {len(combined)} non-drug SMILES to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2b7734",
   "metadata": {},
   "source": [
    "## Combined Dataset\n",
    "\n",
    "Generating a Combined Dataset of both Drugs and Non-drugs\n",
    "- Shuffled.\n",
    "- Assigned target column \"Is Drug\" with 0 for non-drugs and 1 for drugs.\n",
    "\n",
    "Total Molecules = 5901(Drugs) + 5902(Non-Drugs) = 11803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "054f8f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 11803 labeled and shuffled samples to: Dataset/combined/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# File paths\n",
    "# -------------------------\n",
    "drug_file = \"Dataset/positives/dataset.csv\"\n",
    "non_drug_file = \"Dataset/negatives/dataset.csv\"\n",
    "output_file = \"Dataset/combined/dataset.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# Load and label\n",
    "# -------------------------\n",
    "drug_df = pd.read_csv(drug_file)\n",
    "non_drug_df = pd.read_csv(non_drug_file)\n",
    "\n",
    "drug_df[\"Is Drug\"] = 1\n",
    "non_drug_df[\"Is Drug\"] = 0\n",
    "\n",
    "# -------------------------\n",
    "# Combine and shuffle\n",
    "# -------------------------\n",
    "combined_df = pd.concat([drug_df, non_drug_df], ignore_index=True)\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# Save\n",
    "# -------------------------\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Saved {len(combined_df)} labeled and shuffled samples to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353dad4",
   "metadata": {},
   "source": [
    "## Final Dataset\n",
    "\n",
    "Preparing the final dataset with numerical features extracted from the SMILES string.\n",
    "\n",
    "The features extracted are:\n",
    "* Physiochemical\n",
    "  * Molecular Weight\n",
    "  * clogP\n",
    "  * TPSA\n",
    "  * HBD\n",
    "  * HBA\n",
    "  * Rotatable Bonds\n",
    "  * Ring Count\n",
    "* Structural\n",
    "  * EFCP4 (2048-bits)\n",
    "  * MACCS (166-bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b4cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 8188/11803 [00:14<00:06, 550.17it/s][21:29:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:29:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:29:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:29:24] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|██████████| 11803/11803 [00:21<00:00, 552.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final dataset saved to Dataset/final/dataset.csv — shape = (11803, 2223)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Crippen, Lipinski, rdMolDescriptors, MACCSkeys\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# ------------------------\n",
    "# Input/Output\n",
    "# ------------------------\n",
    "input_file = \"Dataset/combined/dataset.csv\"\n",
    "output_file = \"Dataset/final/dataset.csv\"\n",
    "\n",
    "# ------------------------\n",
    "# Initialize Fingerprint Generators\n",
    "# ------------------------\n",
    "morgan_gen = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "# ------------------------\n",
    "# Feature Functions\n",
    "# ------------------------\n",
    "def smiles_to_mol(smiles):\n",
    "    try:\n",
    "        return Chem.MolFromSmiles(smiles)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def compute_features(smiles):\n",
    "    mol = smiles_to_mol(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Physicochemical\n",
    "        mw = Descriptors.MolWt(mol)\n",
    "        logp = Crippen.MolLogP(mol)\n",
    "        tpsa = rdMolDescriptors.CalcTPSA(mol)\n",
    "        hbd = Lipinski.NumHDonors(mol)\n",
    "        hba = Lipinski.NumHAcceptors(mol)\n",
    "        rot_bonds = Lipinski.NumRotatableBonds(mol)\n",
    "        ring_count = rdMolDescriptors.CalcNumRings(mol)\n",
    "\n",
    "        # ECFP4 (2048-bit)\n",
    "        ecfp = morgan_gen.GetFingerprint(mol)\n",
    "        ecfp_bits = list(ecfp)\n",
    "\n",
    "        # MACCS (166-bit)\n",
    "        maccs = MACCSkeys.GenMACCSKeys(mol)\n",
    "        maccs_bits = list(maccs)[1:]  # Remove bit 0\n",
    "\n",
    "        return [mw, logp, tpsa, hbd, hba, rot_bonds, ring_count] + ecfp_bits + maccs_bits\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ------------------------\n",
    "# Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(input_file)\n",
    "df[\"features\"] = df[\"smiles\"].progress_apply(compute_features)\n",
    "\n",
    "# ------------------------\n",
    "# Drop Invalid Entries\n",
    "# ------------------------\n",
    "df = df[df[\"features\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "# ------------------------\n",
    "# Expand Features\n",
    "# ------------------------\n",
    "feature_names = (\n",
    "    [\"MW\", \"clogP\", \"TPSA\", \"HBD\", \"HBA\", \"RotatableBonds\", \"RingCount\"] +\n",
    "    [f\"ECFP4_{i}\" for i in range(2048)] +\n",
    "    [f\"MACCS_{i+1}\" for i in range(166)]\n",
    ")\n",
    "\n",
    "features_df = pd.DataFrame(df[\"features\"].tolist(), columns=feature_names)\n",
    "final_df = pd.concat([df[\"smiles\"], features_df, df[\"Is Drug\"]], axis=1)\n",
    "\n",
    "# ------------------------\n",
    "# Save Final Dataset\n",
    "# ------------------------\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "final_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Final dataset saved to {output_file} — shape = {final_df.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
